

@article{AriyaratneSisith2023AcoC,
issn = {0364-2348},
abstract = {Objective
ChatGPT (Generative Pre-trained Transformer) is an artificial intelligence language tool developed by OpenAI that utilises machine learning algorithms to generate text that closely mimics human language. It has recently taken the internet by storm. There have been several concerns regarding the accuracy of documents it generates. This study compares the accuracy and quality of several ChatGPT-generated academic articles with those written by human authors.
Material and methods
We performed a study to assess the accuracy of ChatGPT-generated radiology articles by comparing them with the published or written, and under review articles. These were independently analysed by two fellowship-trained musculoskeletal radiologists and graded from 1 to 5 (1 being bad and inaccurate to 5 being excellent and accurate).
Results
In total, 4 of the 5 articles written by ChatGPT were significantly inaccurate with fictitious references. One of the papers was well written, with a good introduction and discussion; however, all references were fictitious.
Conclusion
ChatGPT is able to generate coherent research articles, which on initial review may closely resemble authentic articles published by academic researchers. However, all of the articles we assessed were factually inaccurate and had fictitious references. It is worth noting, however, that the articles generated may appear authentic to an untrained reader.},
journal = {Skeletal radiology},
pages = {1755--1758},
volume = {52},
publisher = {Springer Berlin Heidelberg},
number = {9},
year = {2023},
title = {A comparison of ChatGPT-generated articles with human-written articles},
copyright = {The Author(s), under exclusive licence to International Skeletal Society (ISS) 2023. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.},
language = {eng},
address = {Berlin/Heidelberg},
author = {Ariyaratne, Sisith and Iyengar, Karthikeyan. P. and Nischal, Neha and Chitti Babu, Naparla and Botchu, Rajesh},
keywords = {type:quality comparison},
}

@misc{cao2023comprehensive,
      title={A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT}, 
      author={Yihan Cao and Siyu Li and Yixin Liu and Zhiling Yan and Yutong Dai and Philip S. Yu and Lichao Sun},
      year={2023},
      eprint={2303.04226},
      archivePrefix={arXiv},
      primaryClass={cs.AI}，
      keywords = {type:detection techniques},
}

@article{HerboldSteffen2023Alco,
issn = {2045-2322},
abstract = {Abstract ChatGPT and similar generative AI models have attracted hundreds of millions of users and have become part of the public discourse. Many believe that such models will disrupt society and lead to significant changes in the education system and information generation. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models—both lack scientific rigor. We systematically assess the quality of AI-generated content through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays. We use essays that were rated by a large number of human experts (teachers). We augment the analysis by considering a set of linguistic characteristics of the generated essays. Our results demonstrate that ChatGPT generates essays that are rated higher regarding quality than human-written essays. The writing style of the AI models exhibits linguistic characteristics that are different from those of the human-written essays. Since the technology is readily available, we believe that educators must act immediately. We must re-invent homework and develop teaching concepts that utilize these AI models in the same way as math utilizes the calculator: teach the general concepts first and then use AI tools to free up time for other learning objectives.},
journal = {Scientific reports},
pages = {18617--18617},
volume = {13},
publisher = {Nature Publishing Group UK},
number = {1},
year = {2023},
title = {A large-scale comparison of human-written versus ChatGPT-generated essays},
copyright = {The Author(s) 2023},
language = {eng},
address = {London},
author = {Herbold, Steffen and Hautli-Janisz, Annette and Heuer, Ute and Kikteva, Zlata and Trautsch, Alexander},
keywords = {type:quality comparison},
}

@article{ElaliFaisalR.2023Arpf,
issn = {2666-3899},
abstract = {Fabricating research within the scientific community has consequences for one’s credibility and undermines honest authors. We demonstrate the feasibility of fabricating research using an AI-based language model chatbot. Human detection versus AI detection will be compared to determine accuracy in identifying fabricated works. The risks of utilizing AI-generated research works will be underscored and reasons for falsifying research will be highlighted.
Fabricating research within the scientific community has consequences for one’s credibility and undermines honest authors. We demonstrate the feasibility of fabricating research using an AI-based language model chatbot. Human detection versus AI detection will be compared to determine accuracy in identifying fabricated works. The risks of utilizing AI-generated research works will be underscored and reasons for falsifying research will be highlighted.},
journal = {Patterns (New York, N.Y.)},
pages = {100706},
volume = {4},
publisher = {Elsevier Inc},
number = {3},
year = {2023},
title = {AI-generated research paper fabrication and plagiarism in the scientific community},
copyright = {2023 The Author(s)},
language = {eng},
address = {United States},
author = {Elali, Faisal R. and Rachid, Leena N.},
keywords = {type:academic impact},
}

@misc{sadasivan2024aigenerated,
      title={Can AI-Generated Text be Reliably Detected?}, 
      author={Vinu Sankar Sadasivan and Aounon Kumar and Sriram Balasubramanian and Wenxiao Wang and Soheil Feizi},
      year={2024},
      eprint={2303.11156},
      archivePrefix={arXiv},
      primaryClass={cs.CL}，
     keywords = {type:detection techniques},
}

@article{GaoCatherineA2023Csag,
issn = {2398-6352},
abstract = {Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. We gathered fifth research abstracts from five high-impact factor medical journals and asked ChatGPT to generate research abstracts based on their titles and journals. Most generated abstracts were detected using an AI output detector, 'GPT-2 Output Detector', with % 'fake' scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% 'fake' [12.73%, 99.98%] compared with median 0.02% [IQR 0.02%, 0.09%] for the original abstracts. The AUROC of the AI output detector was 0.94. Generated abstracts scored lower than original abstracts when run through a plagiarism detector website and iThenticate (higher scores meaning more matching text found). When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, though abstracts they suspected were generated were vaguer and more formulaic. ChatGPT writes believable scientific abstracts, though with completely generated data. Depending on publisher-specific guidelines, AI output detectors may serve as an editorial tool to help maintain scientific standards. The boundaries of ethical and acceptable use of large language models to help scientific writing are still being discussed, and different journals and conferences are adopting varying policies.},
journal = {NPJ digital medicine},
pages = {75--75},
volume = {6},
publisher = {Nature Publishing Group UK},
number = {1},
year = {2023},
title = {Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers},
copyright = {2023. The Author(s).},
language = {eng},
address = {England},
author = {Gao, Catherine A and Howard, Frederick M and Markov, Nikolay S and Dyer, Emma C and Ramesh, Siddhi and Luo, Yuan and Pearson, Alexander T},
keywords = {type:academic impact},
}

@article{CingilliogluIlker2023DAet,
issn = {2056-4880},
abstract = {PurposeWith the advent of ChatGPT, a sophisticated generative artificial intelligence (AI) tool, maintaining academic integrity in all educational settings has recently become a challenge for educators. This paper discusses a method and necessary strategies to confront this challenge.Design/methodology/approachIn this study, a language model was defined to achieve high accuracy in distinguishing ChatGPT-generated essays from human written essays with a particular focus on “not falsely” classifying genuinely human-written essays as AI-generated (Negative).FindingsVia support vector machine (SVM) algorithm 100% accuracy was recorded for identifying human generated essays. The author discussed the key use of Recall and F2 score for measuring classification performance and the importance of eliminating False Negatives and making sure that no actual human generated essays are incorrectly classified as AI generated. The results of the proposed model's classification algorithms were compared to those of AI-generated text detection software developed by OpenAI, GPTZero and Copyleaks.Practical implicationsAI-generated essays submitted by students can be detected by teachers and educational designers using the proposed language model and machine learning (ML) classifier at a high accuracy. Human (student)-generated essays can and must be correctly identified with 100% accuracy even if the overall classification accuracy performance is slightly reduced.Originality/valueThis is the first and only study that used an n-gram bag-of-words (BOWs) discrepancy language model as input for a classifier to make such prediction and compared the classification results of other AI-generated text detection software in an empirical way.},
journal = {The international journal of information and learning technology},
pages = {259--268},
volume = {40},
publisher = {Emerald Publishing Limited},
number = {3},
year = {2023},
title = {Detecting AI-generated essays: the ChatGPT challenge},
copyright = {Emerald Publishing Limited},
language = {eng},
author = {Cingillioglu, Ilker},
keywords = {type:detection techniques},
}

@article{ElkhatatAhmedM.2023Eteo,
issn = {1833-2595},
abstract = {The proliferation of artificial intelligence (AI)-generated content, particularly from models like ChatGPT, presents potential challenges to academic integrity and raises concerns about plagiarism. This study investigates the capabilities of various AI content detection tools in discerning human and AI-authored content. Fifteen paragraphs each from ChatGPT Models 3.5 and 4 on the topic of cooling towers in the engineering process and five human-witten control responses were generated for evaluation. AI content detection tools developed by OpenAI, Writer, Copyleaks, GPTZero, and CrossPlag were used to evaluate these paragraphs. Findings reveal that the AI detection tools were more accurate in identifying content generated by GPT 3.5 than GPT 4. However, when applied to human-written control responses, the tools exhibited inconsistencies, producing false positives and uncertain classifications. This study underscores the need for further development and refinement of AI content detection tools as AI-generated content becomes more sophisticated and harder to distinguish from human-written text.},
journal = {International journal for educational integrity},
pages = {1--16},
volume = {19},
publisher = {Springer Nature Singapore},
number = {1},
year = {2023},
title = {Evaluating the efficacy of AI content detection tools in differentiating between human and AI-generated text},
copyright = {The Author(s) 2023},
language = {eng},
address = {Singapore},
author = {Elkhatat, Ahmed M. and Elsaid, Khaled and Almeer, Saeed},
keywords = {type:detection techniques},
}

@article{Weber-WulffDebora2023Todt,
issn = {1833-2595},
abstract = {Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for AI-generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AI-generated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text. Furthermore, content obfuscation techniques significantly worsen the performance of tools. The study makes several significant contributions. First, it summarises up-to-date similar scientific and non-scientific efforts in the field. Second, it presents the result of one of the most comprehensive tests conducted so far, based on a rigorous research methodology, an original document set, and a broad coverage of tools. Third, it discusses the implications and drawbacks of using detection tools for AI-generated text in academic settings.},
journal = {International journal for educational integrity},
pages = {1--39},
volume = {19},
publisher = {Springer Nature Singapore},
number = {1},
year = {2023},
title = {Testing of detection tools for AI-generated text},
copyright = {The Author(s) 2023},
language = {eng},
address = {Singapore},
author = {Weber-Wulff, Debora and Anohina-Naumeca, Alla and Bjelobaba, Sonja and Foltýnek, Tomáš and Guerrero-Dib, Jean and Popoola, Olumide and Šigut, Petr and Waddington, Lorna},
keywords = {type:detection techniques},
}

@article{RashidiHoomanH2023TCcH,
issn = {2229-5089},
abstract = {AI Chat Bots such as ChatGPT are revolutionizing our AI capabilities, especially in text generation, to help expedite many tasks, but they introduce new dilemmas. The detection of AI-generated text has become a subject of great debate considering the AI text detector's known and unexpected limitations. Thus far, much research in this area has focused on the detection of AI-generated text; however, the goal of this study was to evaluate the opposite scenario, an AI-text detection tool's ability to discriminate human-generated text. Thousands of abstracts from several of the most well-known scientific journals were used to test the predictive capabilities of these detection tools, assessing abstracts from 1980 to 2023. We found that the AI text detector erroneously identified up to 8% of the known real abstracts as AI-generated text. This further highlights the current limitations of such detection tools and argues for novel detectors or combined approaches that can address this shortcoming and minimize its unanticipated consequences as we navigate this new AI landscape.},
journal = {Journal of pathology informatics},
pages = {100342--100342},
volume = {14},
publisher = {Elsevier},
year = {2023},
title = {The ChatGPT conundrum: Human-generated scientific manuscripts misidentified as AI creations by AI text detection tool},
copyright = {2023 The Author(s).},
language = {eng},
address = {United States},
author = {Rashidi, Hooman H and Fennell, Brandon D and Albahra, Samer and Hu, Bo and Gorbett, Tom},
keywords = {type:academic impact},
}





